from weightErosion import *
from federated import *
from local import *
from loadTrainTest import *

from cumulator import base
import pickle
import os

# === Run the Benchmarking === #

# === parameters for the aggregation Schemes === #

selected_agent_index = 0
num_rounds = 30
epochs = 1

# === parameters for training and testing === #

batch_size = 32


# === Benchmarking Parameters === #

# These are all distributions and number of clients on which we are running our algorithms
distributions = {'A' : [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],
                 'B' : [0, 0, 0, 0, 0.2, 0.6, 0.2, 0, 0, 0],
                 'C' : [0.25, 0.25, 0.25, 0.25, 0, 0, 0, 0, 0, 0],
                 'D' : [0, 0, 0, 0.4, 0.1, 0, 0.1, 0.4, 0, 0],
                 'E' : [0, 0, 0, 0.1, 0.2, 0.4, 0.2, 0.1, 0, 0],
                 'F' : [0, 0, 0.1, 0.1, 0.2, 0.2, 0.2, 0.1, 0.1, 0],
                 'G' : [0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01 ]}

clients = [10, 20, 50, 100]

# We keep track of our computation's carbon footprint
cumulator = base.Cumulator()
cumulator.on()

# Create generated data
results_dir = './generated/pickles'
if not os.path.isdir(results_dir):
    os.makedirs(results_dir)

for name, distribution in distributions.items():
    for num_clients in clients:
        print(' - Number Client %0.3g, distribution %s: %s' % (num_clients, name, distribution))
        train_loader, test_loader = get_non_iid_loader_distribution(num_clients,batch_size,distribution,selected_agent_index)

        dataPickle = []

        # === Run with Weight Erosion aggregation Scheme
        dataPickle.append(run_weight_erosion(train_loader, test_loader, num_clients, batch_size, selected_agent_index, num_rounds, epochs, distribution, distribution_name=name))

        # === Run Federated Learning aggregation Scheme
        dataPickle.append(run_federated(train_loader, test_loader, num_clients, batch_size, selected_agent_index, num_rounds, epochs, distribution, distribution_name=name))

        # === Run Local Training
        dataPickle.append(run_local(train_loader, test_loader, num_clients,batch_size, selected_agent_index, num_rounds, epochs, distribution, distribution_name=name))

        # === Store the results as pickles
        with open(Path.cwd()/'generated'/'pickles'/f'{num_clients}_{name}.pickle', 'wb') as f:
            pickle.dump(dataPickle, f)

cumulator.off()
print(f'The total carbon footprint generated by this benchmark is : {cumulator.total_carbon_footprint()} gCO2eq')
